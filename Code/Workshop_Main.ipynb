{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0epn3CHUDzkt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/modellfabrik/SA_Workshop_Series.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jBNPyhE-TzXs"
      },
      "outputs": [],
      "source": [
        "# Install the ultralytics package\n",
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQKrjG8DUzvm"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUC1mM1aUv6H"
      },
      "outputs": [],
      "source": [
        "# For YOLOv11 object detection, import necessary packages\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRbBUhM4Qf6n"
      },
      "outputs": [],
      "source": [
        "# simple function to plot the detected objects on an image\n",
        "def plot_results(results, boxes=True):\n",
        "    img = results[0].plot(boxes=boxes)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert image to RGB\n",
        "    plt.imshow(img_rgb)  # Display results\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFWRuv9Zp3Mz"
      },
      "source": [
        "### Image Classification with YOLOv11\n",
        "\n",
        "Image classification is the simplest of the tasks and involves classifying an entire image into one of a set of predefined classes.\n",
        "\n",
        "The output of an image classifier is a single class label and a confidence score. Image classification is useful when you need to know only what class an image belongs to and don't need to know where objects of that class are located or what their exact shape is.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/classify/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlQa6TFnqFsa"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model for classification\n",
        "cls_model = YOLO('yolo11s-cls.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBn40PN2qQ_q"
      },
      "outputs": [],
      "source": [
        "## Run inference on the source\n",
        "cls_image_path = '/content/SA_Workshop_Series/Data/bus.jpg'\n",
        "\n",
        "cls_results = cls_model(cls_image_path, save=True, device = 'cpu')\n",
        "\n",
        "plot_results(cls_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkQYV0ieXNn5"
      },
      "source": [
        "### Object detection with YOLOv11\n",
        "\n",
        "Object detection is a task that involves identifying the location and class of objects in an image or video stream.\n",
        "\n",
        "The output of an object detector is a set of bounding boxes that enclose the objects in the image, along with class labels and confidence scores for each box. Object detection is a good choice when you need to identify objects of interest in a scene, but don't need to know exactly where the object is or its exact shape\n",
        "\n",
        "https://docs.ultralytics.com/tasks/detect/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glKDsRAkXG2C"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model for object detection\n",
        "det_model = YOLO('yolo11s.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62KdTfJuVDvp"
      },
      "outputs": [],
      "source": [
        "# Set image path to a variable\n",
        "det_image_path = '/content/SA_Workshop_Series/Data/bus.jpg'\n",
        "\n",
        "# Open Image with PIL library\n",
        "det_img = Image.open(det_image_path)\n",
        "det_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnipdvXVpetF"
      },
      "outputs": [],
      "source": [
        "## Run inference on the source\n",
        "det_results = det_model(det_img, save=True, device = 'cpu', conf=0.5, imgsz=(1920, 1080))\n",
        "\n",
        "## Run inference on with arguments\n",
        "# show_boxes = False\n",
        "# conf = 0.5\n",
        "# imgsz = 640\n",
        "# classes = [0, 1]\n",
        "\n",
        "\n",
        "plot_results(det_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-J-bTtZeotj"
      },
      "source": [
        "### Segmentation with YOLOv11\n",
        "\n",
        "Instance segmentation goes a step further than object detection and involves identifying individual objects in an image and segmenting them from the rest of the image.\n",
        "\n",
        "The output of an instance segmentation model is a set of masks or contours that outline each object in the image, along with class labels and confidence scores for each object. Instance segmentation is useful when you need to know not only where objects are in an image, but also what their exact shape is.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/segment/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTRPE-4pfIEE"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model for segmentation\n",
        "seg_model = YOLO('yolo11s-seg.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElS80xobfQH6"
      },
      "outputs": [],
      "source": [
        "# Set image path to a variable\n",
        "seg_image_path = '/content/SA_Workshop_Series/Data/Sample_Image_traffic.jpg'\n",
        "\n",
        "# Open Image with PIL library\n",
        "seg_img = Image.open(seg_image_path)\n",
        "seg_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB69avoufc9i"
      },
      "outputs": [],
      "source": [
        "## Run inference on the image\n",
        "seg_results = seg_model(seg_img, save=False, device = 'cpu', conf=0.3, show_boxes=False)\n",
        "\n",
        "plot_results(seg_results, boxes=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yQHpnWv0-a5"
      },
      "source": [
        "### Pose estimation with YOLOv11\n",
        "\n",
        "With pose estimation, you can identify the pose of a person in an image or video stream. The pose estimator outputs key points for each person detected as well as a confidence score for each key point. This is useful if you need to know the position of a person's body parts (e.g. eyes, shoulders, hips).\n",
        "\n",
        "https://docs.ultralytics.com/tasks/pose/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-jfFN7O1ayO"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model for pose estimation\n",
        "pose_model = YOLO('yolo11s-pose.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwpUocun1arf"
      },
      "outputs": [],
      "source": [
        "# Set image path to a variable\n",
        "pose_image_path = '/content/SA_Workshop_Series/Data/Man_Walking.jpg'\n",
        "# link = 'https://img.freepik.com/free-photo/group-people-performing-stretching-exercise_1170-116.jpg'\n",
        "\n",
        "# Open Image with PIL library\n",
        "pose_img = Image.open(pose_image_path)\n",
        "pose_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRY5_45f1al_"
      },
      "outputs": [],
      "source": [
        "## Run inference on the image\n",
        "pose_results = pose_model(pose_img, save=True, device = 'cpu', conf=0.8)\n",
        "\n",
        "plot_results(pose_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhKZQ6d15KvT"
      },
      "source": [
        "### Oriented Bounding Box with YOLOv11\n",
        "\n",
        "Oriented object detection goes a step further than standard object detection by introducing an extra angle to locate objects more accurately in an image.\n",
        "\n",
        "The output of an oriented object detector is a set of rotated bounding boxes that precisely enclose the objects in the image, along with class labels and confidence scores for each box.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/obb/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhoedu711acg"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model for pose estimation\n",
        "obb_model = YOLO('yolo11s-obb.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX03ENnR5dpj"
      },
      "outputs": [],
      "source": [
        "# Set image path to a variable\n",
        "obb_image_path = '/content/SA_Workshop_Series/Data/Ship_Image.png'\n",
        "\n",
        "# Open Image with PIL library\n",
        "obb_img = Image.open(obb_image_path)\n",
        "obb_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GBVTXsE5jcL"
      },
      "outputs": [],
      "source": [
        "## Run inference on the image\n",
        "obb_results = obb_model(obb_img, save=True, device = 'cpu', conf=0.3, imgsz=(1359, 1112))\n",
        "\n",
        "obb_result_pil = obb_results[0].plot(font_size=20, line_width=8, pil=True)      # font=8, line=3\n",
        "obb_result_image = np.array(obb_result_pil)\n",
        "cv2_imshow(obb_result_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi9fWWGq66bi"
      },
      "source": [
        "### Run Object detection on a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40MtAgXz64io"
      },
      "outputs": [],
      "source": [
        "## Run inference on a video\n",
        "\n",
        "det_video_path =  '/content/SA_Workshop_Series/Data/Traffic_video.mp4'\n",
        "det_results_video = det_model(det_video_path, save=True, device = 'cpu', conf=0.5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ME0mJS8Byj"
      },
      "source": [
        "### Run Pose Estimation on a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfRFpaXa8KkJ"
      },
      "outputs": [],
      "source": [
        "pose_video_path =  '/content/SA_Workshop_Series/Data/Person_walking.mp4'\n",
        "pose_results_video = det_model(pose_video_path, save=True, device = 0, conf=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycjS_tf--v0v"
      },
      "source": [
        "### Object detection Excercise\n",
        "\n",
        "#### Let us now apply object detection model to a car parking example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF7mV2cT_aeX"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Predict on an image\n",
        "results = model('/content/SA_Workshop_Series/Data/Parking_Cars.jpg', classes=2)\n",
        "\n",
        "# Plot the results\n",
        "plot_results(results)\n",
        "\n",
        "\n",
        "print(f\"Detected {len(results[0])} cars.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get the bounding box coordinates and the width and height of the bounding boxes of the detected cars in the image below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph8HGtFl_0m_"
      },
      "outputs": [],
      "source": [
        "for box in results[0].boxes:\n",
        "    w = box.xywh[0][2].item() # width\n",
        "    h = box.xywh[0][3].item() # height\n",
        "    x = box.xywh[0][0].item() - w/2 # x-coordinate\n",
        "    y = box.xywh[0][1].item() - h/2 # y-coordinate\n",
        "    print(f\"Box at ({x}, {y}) with width {w} and height {h}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Make a program that checks, if a car is on the parking spot below the sign on the right using the coordinates of the bounding box."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9VOBodK__HE"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Load a pre-trained model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Predict on an image\n",
        "results = model('/content/SA_Workshop_Series/Data/Parking_Cars.jpg', classes=2)\n",
        "\n",
        "def plot_box(x, y, w, h, img, title=\"\", color='r'):\n",
        "    # Define Matplotlib figure and axis\n",
        "    _, ax = plt.subplots()\n",
        "\n",
        "    # Display the image\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
        "    ax.set_title(title, color=color)\n",
        "    ax.imshow(img_rgb)\n",
        "\n",
        "    # Add rectangle to plot\n",
        "    rect = Rectangle((x, y), w, h, linewidth=1, edgecolor=color, facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    # Display plot\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "parking_spot = [1350, 600, 200, 175]\n",
        "\n",
        "plot_box(*parking_spot, results[0].orig_img, title=\"Parking spot\", color='b')\n",
        "\n",
        "for box in results[0].boxes:\n",
        "    w = box.xywh[0][2].item() # width\n",
        "    h = box.xywh[0][3].item() # height\n",
        "    x = box.xywh[0][0].item() - w/2 # x-coordinate\n",
        "    y = box.xywh[0][1].item() - h/2 # y-coordinate\n",
        "\n",
        "    img = results[0].orig_img # Get the original image\n",
        "\n",
        "    # Check if the two boxes intersect\n",
        "    if (x < parking_spot[0] + parking_spot[2] and x + w > parking_spot[0] and y < parking_spot[1] + parking_spot[3] and y + h > parking_spot[1]):\n",
        "        plot_box(x, y, w, h, img, title=\"Car is inside the parking spot.\", color='g')\n",
        "    else:\n",
        "        plot_box(x, y, w, h, img, title=\"Car is not inside the parking spot.\", color='r')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
