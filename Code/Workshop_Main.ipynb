{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0epn3CHUDzkt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/modellfabrik/SA_Workshop_Series.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jBNPyhE-TzXs"
      },
      "outputs": [],
      "source": [
        "# Install the ultralytics package\n",
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQKrjG8DUzvm"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUC1mM1aUv6H"
      },
      "outputs": [],
      "source": [
        "# Für die YOLOv11-Objekterkennung, importieren die notwendigen Pakete\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRbBUhM4Qf6n"
      },
      "outputs": [],
      "source": [
        "# einfache Funktion zur Darstellung der erkannten Objekte auf einem Bild\n",
        "def plot_results(results, boxes=True):\n",
        "    img = results[0].plot(boxes=boxes)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Bild in RGB umwandeln\n",
        "    plt.imshow(img_rgb)  # Ergebnisse anzeigen\n",
        "    plt.axis('off')  # Achsen ausblenden\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFWRuv9Zp3Mz"
      },
      "source": [
        "### Bildklassifizierung mit YOLOv11\n",
        "\n",
        "Die Bildklassifizierung ist die einfachste Aufgabe – dabei ordnest du ein ganzes Bild einer von mehreren vordefinierten Klassen zu.\n",
        "\n",
        "Die Ausgabe eines Bildklassifizierers ist eine einzelne Klassenbezeichnung und ein Vertrauenswert. Die Bildklassifizierung ist dann nützlich, wenn du nur wissen musst, zu welcher Klasse ein Bild gehört – und nicht, wo sich die Objekte dieser Klasse befinden oder welche Form sie genau haben.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/classify/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlQa6TFnqFsa"
      },
      "outputs": [],
      "source": [
        "# Lade das vortrainierte Modell zur Klassifizierung\n",
        "cls_model = YOLO('yolo11s-cls.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBn40PN2qQ_q"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf die Quelle ausführen\n",
        "cls_image_path = '/content/SA_Workshop_Series/Data/Screwdriver.jpg'\n",
        "\n",
        "cls_results = cls_model(cls_image_path, save=True, device = 'cpu')\n",
        "\n",
        "plot_results(cls_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkQYV0ieXNn5"
      },
      "source": [
        "### Objekterkennung mit YOLOv11\n",
        "\n",
        "Objekterkennung ist eine Aufgabe, bei der es darum geht, die Position und Klasse von Objekten in einem Bild oder Videostream zu identifizieren.\n",
        "\n",
        "Die Ausgabe eines Objekterkenners ist eine Menge von Begrenzungsrahmen, die die Objekte im Bild umschließen, zusammen mit Klassenbezeichnungen und Vertrauenswerten für jeden Rahmen. Die Objekterkennung ist eine gute Wahl, wenn du Objekte von Interesse in einer Szene identifizieren musst, aber nicht genau wissen musst, wo sich das Objekt befindet oder welche exakte Form es hat.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/detect/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glKDsRAkXG2C"
      },
      "outputs": [],
      "source": [
        "# Lade das vortrainierte Modell zur Objekterkennung\n",
        "det_model = YOLO('yolo11s.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62KdTfJuVDvp"
      },
      "outputs": [],
      "source": [
        "# Bildpfad auf eine Variable setzen\n",
        "det_image_path = '/content/SA_Workshop_Series/Data/bus.jpg'\n",
        "\n",
        "# Bild mit PIL-Bibliothek öffnen\n",
        "det_img = Image.open(det_image_path)\n",
        "det_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnipdvXVpetF"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf die Quelle ausführen\n",
        "det_results = det_model(det_img, save=True, device = 'cpu', conf=0.99)\n",
        "\n",
        "## Inferenz mit Argumenten einschalten\n",
        "# show_boxes = False\n",
        "# conf = 0.25\n",
        "# imgsz = 640\n",
        "# classes = [0, 1]\n",
        "# class_bus = 5\n",
        "# iou = 0.7\n",
        "\n",
        "\n",
        "\n",
        "plot_results(det_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-J-bTtZeotj"
      },
      "source": [
        "### Segmentierung mit YOLOv11\n",
        "\n",
        "Die Instanzsegmentierung geht einen Schritt weiter als die Objekterkennung und beinhaltet das Erkennen einzelner Objekte in einem Bild sowie deren Abgrenzung vom Rest des Bildes.\n",
        "\n",
        "Die Ausgabe eines Instanzsegmentierungsmodells ist eine Menge von Masken oder Konturen, die jedes Objekt im Bild umreißen, zusammen mit Klassenbezeichnungen und Vertrauenswerten für jedes Objekt. Die Instanzsegmentierung ist hilfreich, wenn du nicht nur wissen musst, wo sich Objekte in einem Bild befinden, sondern auch, welche genaue Form sie haben.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/segment/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTRPE-4pfIEE"
      },
      "outputs": [],
      "source": [
        "# Lade das vortrainierte Modell zur Segmentierung\n",
        "seg_model = YOLO('yolo11s-seg.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElS80xobfQH6"
      },
      "outputs": [],
      "source": [
        "# Bildpfad auf eine Variable setzen\n",
        "seg_image_path = '/content/SA_Workshop_Series/Data/Sample_Image_traffic.jpg'\n",
        "\n",
        "# Bild mit PIL-Bibliothek öffnen\n",
        "seg_img = Image.open(seg_image_path)\n",
        "seg_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB69avoufc9i"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf das Bild anwenden\n",
        "seg_results = seg_model(seg_img, save=False, device = 'cpu', conf=0.3, show_boxes=False)\n",
        "\n",
        "plot_results(seg_results, boxes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yQHpnWv0-a5"
      },
      "source": [
        "### Pose estimation mit YOLOv11\n",
        "\n",
        "Mit der Posen­schätzung kannst du die Körperhaltung einer Person in einem Bild oder Videostream erkennen. Der Posen­schätzer gibt Schlüsselpunkte für jede erkannte Person sowie einen Vertrauenswert für jeden Punkt aus. Das ist nützlich, wenn du die Position einzelner Körperteile einer Person (z. B. Augen, Schultern, Hüften) wissen musst.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/pose/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-jfFN7O1ayO"
      },
      "outputs": [],
      "source": [
        "# Lade das vortrainierte Modell zur Pose Estimation\n",
        "pose_model = YOLO('yolo11s-pose.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwpUocun1arf"
      },
      "outputs": [],
      "source": [
        "# Bildpfad auf eine Variable setzen\n",
        "pose_image_path = '/content/SA_Workshop_Series/Data/Man_Walking.jpg'\n",
        "# link = 'https://img.freepik.com/free-photo/group-people-performing-stretching-exercise_1170-116.jpg'\n",
        "\n",
        "# Bild mit PIL-Bibliothek öffnen\n",
        "pose_img = Image.open(pose_image_path)\n",
        "pose_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRY5_45f1al_"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf das Bild anwenden\n",
        "pose_results = pose_model(pose_img, save=True, device = 'cpu')\n",
        "\n",
        "plot_results(pose_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhKZQ6d15KvT"
      },
      "source": [
        "### Oriented Bounding Box mit YOLOv11\n",
        "\n",
        "Die orientierte Objekterkennung geht einen Schritt weiter als die klassische Objekterkennung, indem sie einen zusätzlichen Winkel einführt, um Objekte im Bild genauer zu lokalisieren.\n",
        "\n",
        "Die Ausgabe eines orientierten Objekterkenners ist eine Menge von gedrehten Begrenzungsrahmen, die die Objekte im Bild präzise umschließen, zusammen mit Klassenbezeichnungen und Vertrauenswerten für jeden Rahmen.\n",
        "\n",
        "https://docs.ultralytics.com/tasks/obb/#models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhoedu711acg"
      },
      "outputs": [],
      "source": [
        "# Lade das vortrainierte Modell zur OBB\n",
        "obb_model = YOLO('yolo11s-obb.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX03ENnR5dpj"
      },
      "outputs": [],
      "source": [
        "# Bildpfad auf eine Variable setzen\n",
        "obb_image_path = '/content/SA_Workshop_Series/Data/Ship_Image.png'\n",
        "\n",
        "# Bild mit PIL-Bibliothek öffnen\n",
        "obb_img = Image.open(obb_image_path)\n",
        "obb_img.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GBVTXsE5jcL"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf das Bild anwenden\n",
        "obb_results = obb_model(obb_img, save=True, device = 'cpu', conf=0.3, imgsz=(1359, 1112))\n",
        "\n",
        "obb_result_pil = obb_results[0].plot(font_size=20, line_width=8, pil=True)      # font=8, line=3\n",
        "obb_result_image = np.array(obb_result_pil)\n",
        "cv2_imshow(obb_result_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi9fWWGq66bi"
      },
      "source": [
        "### Objekterkennung für ein Video durchführen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40MtAgXz64io"
      },
      "outputs": [],
      "source": [
        "## Inferenz auf ein Video anwenden\n",
        "\n",
        "det_video_path =  '/content/SA_Workshop_Series/Data/Traffic_video.mp4'\n",
        "det_results_video = det_model(det_video_path, save=True, device = 'cpu', conf=0.5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ME0mJS8Byj"
      },
      "source": [
        "### Pose Estimation für ein Video ausführen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfRFpaXa8KkJ"
      },
      "outputs": [],
      "source": [
        "pose_video_path =  '/content/SA_Workshop_Series/Data/Person_walking.mp4'\n",
        "pose_results_video = det_model(pose_video_path, save=True, device = 0, conf=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycjS_tf--v0v"
      },
      "source": [
        "### Objekterkennung Übung\n",
        "\n",
        "#### Wenden wir nun das Objekterkennungsmodell auf ein Beispiel für ein parkendes Auto an"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF7mV2cT_aeX"
      },
      "outputs": [],
      "source": [
        "# Laden Sie ein vortrainiertes Modell\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Vorhersage auf einem Bild\n",
        "results = model('/content/SA_Workshop_Series/Data/Parking_Cars.jpg', classes=2)\n",
        "\n",
        "# Zeichnen Sie die Ergebnisse auf\n",
        "plot_results(results)\n",
        "\n",
        "\n",
        "print(f\"Detected {len(results[0])} cars.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Ermitteln Sie die Bounding-Box-Koordinaten sowie die Breite und Höhe der Bounding-Boxen der erkannten Fahrzeuge im folgenden Bild."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph8HGtFl_0m_"
      },
      "outputs": [],
      "source": [
        "for box in results[0].boxes:\n",
        "    w = box.xywh[0][2].item() # Breite\n",
        "    h = box.xywh[0][3].item() # Höhe\n",
        "    x = box.xywh[0][0].item() - w/2 # x-Koordinate\n",
        "    y = box.xywh[0][1].item() - h/2 # y-Koordinate\n",
        "    print(f\"Box at ({x}, {y}) with width {w} and height {h}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Erstellen Sie ein Programm, das anhand der Koordinaten des Begrenzungsrahmens prüft, ob sich ein Auto auf dem Parkplatz unterhalb des Schildes rechts befindet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9VOBodK__HE"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Lade ein vortrainiertes Modell\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Vorhersage auf einem Bild\n",
        "results = model('/content/SA_Workshop_Series/Data/Parking_Cars.jpg', classes=2)\n",
        "\n",
        "def plot_box(x, y, w, h, img, title=\"\", color='r'):\n",
        "    # Matplotlib-Figur und -Achse definieren\n",
        "    _, ax = plt.subplots()\n",
        "\n",
        "    # Anzeige des Bildes\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Bild in RGB umwandeln\n",
        "    ax.set_title(title, color=color)\n",
        "    ax.imshow(img_rgb)\n",
        "\n",
        "    # Rechteck zum Plot hinzufügen\n",
        "    rect = Rectangle((x, y), w, h, linewidth=1, edgecolor=color, facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "    # Plot anzeigen\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "parking_spot = [1350, 600, 200, 175]\n",
        "\n",
        "plot_box(*parking_spot, results[0].orig_img, title=\"Parking spot\", color='b')\n",
        "\n",
        "for box in results[0].boxes:\n",
        "    w = box.xywh[0][2].item() # Breite\n",
        "    h = box.xywh[0][3].item() # Höhe\n",
        "    x = box.xywh[0][0].item() - w/2 # x-Koordinate\n",
        "    y = box.xywh[0][1].item() - h/2 # y-Koordinate\n",
        "\n",
        "    img = results[0].orig_img # Hole das Originalbild\n",
        "\n",
        "    # Überprüfe, ob sich die beiden Kästchen schneiden\n",
        "    if (x < parking_spot[0] + parking_spot[2] and x + w > parking_spot[0] and y < parking_spot[1] + parking_spot[3] and y + h > parking_spot[1]):\n",
        "        plot_box(x, y, w, h, img, title=\"Car is inside the parking spot.\", color='g')\n",
        "    else:\n",
        "        plot_box(x, y, w, h, img, title=\"Car is not inside the parking spot.\", color='r')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
